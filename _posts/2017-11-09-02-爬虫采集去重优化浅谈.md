---
layout: post
title: 爬虫采集去重优化浅谈
subtitle: 2017/11/09
date: 2017-11-09
author: FR
header-img: img/depot/post-butiao.jpg
catalog: true
tags:
    - 爬虫
---

- **来自FreeBuf [【FreeBuf链接】](http://www.freebuf.com/articles/others-articles/151173.html)**  

以前在做漏洞Fuzz爬虫时，曾做过URL去重相关的工作，当时是参考了seay法师的文章以及网上零碎的一些资料，感觉做的很简单。近来又遇到相关问题，于是乎有了再次改进算法的念头。

首先，针对URL本身的去重，可以直接对整块URL进行处理。在参考网上的一些文章时，发现它们大多采用了 URL 压缩存储的方法。不过使用这些算法在数据量较大的时候，能大幅减小存储的空间：
